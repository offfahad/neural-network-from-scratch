{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f60dc9",
   "metadata": {},
   "source": [
    "# TASK 3\n",
    "\n",
    "# Part 1 - Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47572da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs,weights and bias and calculation\n",
    "inputs = [1.2, 5.2, 2.1]\n",
    "weights = [3.1, 2.1, 8.1]\n",
    "bias = 3\n",
    "layer_output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7bdc42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Before Activation: 34.650000000000006\n"
     ]
    }
   ],
   "source": [
    "print(\"Output Before Activation:\", layer_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee6a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom activation function\n",
    "def custom_binary_activation(x):\n",
    "    threshold = 50.0 \n",
    "    return 1 if x > threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3a0e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Activation Function Output: 0\n"
     ]
    }
   ],
   "source": [
    "custom_activation_ouput = custom_binary_activation(layer_output)\n",
    "print(\"Custom Activation Function Output:\", custom_activation_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62b9fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the sigmoid activation function\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd31ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Activation Function Output: 0.9999999999999991\n"
     ]
    }
   ],
   "source": [
    "output = sigmoid(layer_output)\n",
    "print(\"Sigmoid Activation Function Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5f054",
   "metadata": {},
   "source": [
    "# Part 2 - Single Layer Neural Network With Random Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a095569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input values\n",
    "inputs = [1.2, 5.2, 2.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b6e3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random weights and bias\n",
    "random_weights = np.random.rand(3)   \n",
    "random_bias = np.random.randint(1, 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c18b9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights: [0.75378307 0.24678429 0.98437245]\n",
      "Random Bias: 52\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Weights:\", random_weights)\n",
    "print(\"Random Bias:\", random_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9a769df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted sum of inputs and add bias\n",
    "layer_output = np.dot(inputs, random_weights) + random_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45072c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Before Activation: 56.25500013829941\n"
     ]
    }
   ],
   "source": [
    "print(\"Output Before Activation:\", layer_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c6a5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Activation Function Output: 1\n"
     ]
    }
   ],
   "source": [
    "custom_activation_ouput = custom_binary_activation(layer_output)\n",
    "print(\"Custom Activation Function Output:\", custom_activation_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad854467",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_activation_output = sigmoid(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8faf9068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Activation Function Output: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sigmoid Activation Function Output:\", sigmoid_activation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f955a56c",
   "metadata": {},
   "source": [
    "# Part 3 - Multi Layer Neural Network With Multiple Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db970e",
   "metadata": {},
   "source": [
    "### Input Layer With Multiple Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b07c95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input values\n",
    "inputs = np.array([1.2, 5.2, 2.1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b74d3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weights = np.random.rand(3, 3) # Change the shape (3, 3) as needed\n",
    "random_biases = np.random.randint(1, 101, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc6e506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Generated Weights:\n",
      "[[0.75540676 0.09981784 0.16583715]\n",
      " [0.95627156 0.58356671 0.23705143]\n",
      " [0.32029218 0.84086923 0.86238068]]\n",
      "Randomly Generated Biases: [79 84  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Randomly Generated Weights:\")\n",
    "print(random_weights)\n",
    "print(\"Randomly Generated Biases:\", random_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce7c0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted sums for each neuron\n",
    "input_layer_output_without_activation = np.dot(inputs, random_weights) + random_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7231f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer Before Activation: [85.55171379 88.92015365  4.24267143]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Layer Before Activation:\", input_layer_output_without_activation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "316a2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_binary_activation_multivalues(values):\n",
    "    threshold = 50.0\n",
    "    return np.where(values > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9625be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Activation Function Output: [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "custom_activation_output = custom_binary_activation_multivalues(input_layer_output_without_activation)\n",
    "print(\"Custom Activation Function Output:\", custom_activation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0331640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_sigmoid_activation_output = sigmoid(input_layer_output_without_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5672b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Activation Function Output For Input Layer: [1.         1.         0.98583439]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sigmoid Activation Function Output For Input Layer:\", input_layer_sigmoid_activation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62781aee",
   "metadata": {},
   "source": [
    "### Hidden Layer With Multiple Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b246fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weights = np.random.rand(3, 3) # Change the shape (3, 3) as needed\n",
    "random_biases = np.random.randint(1, 101, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94a3970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Generated Weights:\n",
      "[[0.69008988 0.85615367 0.17134403]\n",
      " [0.56837014 0.03065268 0.88092611]\n",
      " [0.09014917 0.10189541 0.4258336 ]]\n",
      "Randomly Generated Biases: [25  5 84]\n"
     ]
    }
   ],
   "source": [
    "print(\"Randomly Generated Weights:\")\n",
    "print(random_weights)\n",
    "print(\"Randomly Generated Biases:\", random_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a77cdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted sums for each neuron\n",
    "hidden_layer_output_without_activation = np.dot(input_layer_sigmoid_activation_output, random_weights) + random_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b90ebd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Output Before Activation: [26.59240958  6.59240958 85.59240958]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hidden Layer Output Before Activation:\", hidden_layer_output_without_activation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5bb59ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Activation Function Output: [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "custom_activation_output = custom_binary_activation_multivalues(hidden_layer_output_without_activation)\n",
    "print(\"Custom Activation Function Output:\", custom_activation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce225c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sigmoid_activation_output = sigmoid(hidden_layer_output_without_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "79c59264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Activation Function Output For Hidden Layer: [1.         0.99863114 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sigmoid Activation Function Output For Hidden Layer:\", hidden_layer_sigmoid_activation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73a4eb",
   "metadata": {},
   "source": [
    "### Output With Single Layer Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce803152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random weights and bias\n",
    "random_weights = np.random.rand(3)   \n",
    "random_bias = np.random.randint(1, 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5b1e3822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights: [0.03108971 0.22688415 0.4645361 ]\n",
      "Random Bias: 70\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Weights:\", random_weights)\n",
    "print(\"Random Bias:\", random_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df1fdf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted sum of inputs and add bias\n",
    "output_layer_before_activation = np.dot(hidden_layer_sigmoid_activation_output, random_weights) + random_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dfd19321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Layer Before Activation: 70.72219939426297\n"
     ]
    }
   ],
   "source": [
    "print(\"Output Layer Before Activation:\", output_layer_before_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6579f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Activation Function Output: 1\n"
     ]
    }
   ],
   "source": [
    "custom_activation_ouput = custom_binary_activation(output_layer_before_activation)\n",
    "print(\"Custom Activation Function Output:\", custom_activation_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c9f729a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_activation_output = sigmoid(output_layer_before_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9ef01134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final layer Output After Sigmoid Activation Function 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Final layer Output After Sigmoid Activation Function\", sigmoid_activation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83bbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
